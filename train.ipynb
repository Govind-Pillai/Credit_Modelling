{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8718b17e-4a16-4290-a6f7-675290348c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f79dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = ['Credit_Score', 'Age_Oldest_TL', 'enq_L3m', 'enq_L6m', 'num_std', 'time_since_recent_enq', 'num_std_12mts', 'pct_PL_enq_L6m_of_L12m', 'num_std_6mts', 'time_since_recent_deliquency','Approved_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97a507a7-3c8e-4820-86a0-6b2af88c259a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Credit_Score  Age_Oldest_TL  enq_L3m  enq_L6m  num_std  \\\n",
      "0               696             72        0        0       21   \n",
      "1               685              7        0        0        0   \n",
      "2               693             47        0        0       10   \n",
      "3               673              5   -99999   -99999        5   \n",
      "4               753            131        0        0       53   \n",
      "...             ...            ...      ...      ...      ...   \n",
      "51331           650             24        1        3        0   \n",
      "51332           702             74        0        0        6   \n",
      "51333           661              9        2        4        0   \n",
      "51334           686             15        0        0        0   \n",
      "51335           681             20        1        1       18   \n",
      "\n",
      "       time_since_recent_enq  num_std_12mts  pct_PL_enq_L6m_of_L12m  \\\n",
      "0                        566             11                     0.0   \n",
      "1                        209              0                     0.0   \n",
      "2                        587             10                     0.0   \n",
      "3                     -99999              5                     0.0   \n",
      "4                       3951             16                     0.0   \n",
      "...                      ...            ...                     ...   \n",
      "51331                      0              0                     0.0   \n",
      "51332                    203              6                     0.0   \n",
      "51333                      1              0                     1.0   \n",
      "51334                    242              0                     0.0   \n",
      "51335                     13             10                     0.0   \n",
      "\n",
      "       num_std_6mts  time_since_recent_deliquency Approved_Flag  \n",
      "0                 5                            15            P2  \n",
      "1                 0                        -99999            P2  \n",
      "2                 5                             3            P2  \n",
      "3                 4                        -99999            P2  \n",
      "4                 4                        -99999            P1  \n",
      "...             ...                           ...           ...  \n",
      "51331             0                            23            P4  \n",
      "51332             4                        -99999            P1  \n",
      "51333             0                        -99999            P3  \n",
      "51334             0                        -99999            P2  \n",
      "51335             4                        -99999            P2  \n",
      "\n",
      "[51336 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_excel(\"C:/Users/Admin/Python Techpaathshala/Credit_Modelling/case_study1.xlsx\")\n",
    "df2 = pd.read_excel(\"C:/Users/Admin/Python Techpaathshala/Credit_Modelling/case_study2.xlsx\")\n",
    "df = pd.merge(df1, df2, on='PROSPECTID', how='inner')\n",
    "df = df.drop(columns=['PROSPECTID'])\n",
    "#cols_to_drop = [col for col in df.columns if (df[col] == -99999).sum() > 10000]\n",
    "#df_cleaned = df.drop(columns=cols_to_drop)\n",
    "#for col in df_cleaned.columns:\n",
    "#    df_cleaned = df_cleaned[df_cleaned[col] != -99999]\n",
    "\n",
    "df_cleaned = df[important_features]\n",
    "\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30566d9e-f48b-4de4-b455-5621bee6e32e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Extract feature names from the preprocessor\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m rf_preprocessor = \u001b[43mrf_pipeline\u001b[49m.named_steps[\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m feature_names = preprocessor.get_feature_names_out()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Extract feature importances from the classifier\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'rf_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract feature names from the preprocessor\n",
    "rf_preprocessor = rf_pipeline.named_steps['preprocessor']\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Extract feature importances from the classifier\n",
    "rf_importances = rf_pipeline.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Create and sort the importance DataFrame\n",
    "rf_feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "rf_feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Only look at the Top 15\n",
    "print(rf_feature_importance_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6852e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names from the preprocessor\n",
    "gb_preprocessor = gb_pipeline.named_steps['preprocessor']\n",
    "\n",
    "# Extract feature importances from the classifier\n",
    "gb_importances = gb_pipeline.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Create and sort the importance DataFrame\n",
    "gb_feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "gb_feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Only look at the Top 15\n",
    "print(gb_feature_importance_df.head(15))\n",
    "important_features = []\n",
    "\n",
    "for i in gb_feature_importance_df.head(15)['Feature']:\n",
    "    important_features.append(i)\n",
    "    \n",
    "    \n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4bdcd31",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LabelEncoder() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 5. Define Preprocessing Pipeline\u001b[39;00m\n\u001b[32m     15\u001b[39m num_transformer = Pipeline(steps=[\n\u001b[32m     16\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mimputer\u001b[39m\u001b[33m'\u001b[39m, SimpleImputer(strategy=\u001b[33m'\u001b[39m\u001b[33mmedian\u001b[39m\u001b[33m'\u001b[39m)),\n\u001b[32m     17\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m'\u001b[39m, StandardScaler())\n\u001b[32m     18\u001b[39m     ])\n\u001b[32m     20\u001b[39m cat_transformer = Pipeline(steps=[\n\u001b[32m     21\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mimputer\u001b[39m\u001b[33m'\u001b[39m, SimpleImputer(strategy=\u001b[33m'\u001b[39m\u001b[33mmost_frequent\u001b[39m\u001b[33m'\u001b[39m)),\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mLabelEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     23\u001b[39m     ])\n\u001b[32m     25\u001b[39m preprocessor = ColumnTransformer(\n\u001b[32m     26\u001b[39m         transformers=[\n\u001b[32m     27\u001b[39m             (\u001b[33m'\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m'\u001b[39m, num_transformer, num_cols),\n\u001b[32m     28\u001b[39m             (\u001b[33m'\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m'\u001b[39m, cat_transformer, cat_cols)\n\u001b[32m     29\u001b[39m         ]\n\u001b[32m     30\u001b[39m     )\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# 6. Split Data\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: LabelEncoder() takes no arguments"
     ]
    }
   ],
   "source": [
    "# 4. Feature Selection\n",
    "target = 'Approved_Flag'\n",
    "X = df_cleaned.drop(columns=[target])\n",
    "y = df_cleaned[target]\n",
    "\n",
    "# Label encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Identify numerical and categorical columns for the pipeline\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# 5. Define Preprocessing Pipeline\n",
    "num_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('label', LabelEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols),\n",
    "            ('cat', cat_transformer, cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 6. Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # 7. Model Training - Random Forest Pipeline\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "print(\"Training Random Forest...\")\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 8. Model Training - Gradient Boosting Pipeline\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "print(\"Training Gradient Boosting...\")\n",
    "gb_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18667f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.9952278924814959\n",
      "Random Forest Accuracy: 0.9887027658745617\n"
     ]
    }
   ],
   "source": [
    "y_pred_gb = gb_pipeline.predict(X_test)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c23d8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 9. Save Models and Label Encoder as Pickle Files\n",
    "with open('random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_pipeline, f)\n",
    "\n",
    "with open('gradient_boosting_model.pkl', 'wb') as f:\n",
    "    pickle.dump(gb_pipeline, f)\n",
    "\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"Training complete. Models saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
